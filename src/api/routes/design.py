"""
Nexus AI Design Module API Routes
è®¾è®¡æ¨¡å— API è·¯ç”±

æä¾›ï¼š
- å›¾åƒç”Ÿæˆ (æ”¯æŒå¤šæ¨¡å‹)
- AI è®¾è®¡å¯¹è¯ (ä½¿ç”¨ Grok)
- é¡¹ç›®æŒä¹…åŒ– (ä½¿ç”¨ Supabase)
- å…ƒç´ æ‹†åˆ† (SAM + OCR + Inpainting)
- è§†é¢‘ç”Ÿæˆ (é¢„ç•™)
"""

import os
import base64
import logging
import uuid
from typing import Optional, List, Dict, Any
from fastapi import APIRouter, HTTPException, UploadFile, File
from pydantic import BaseModel, Field
from datetime import datetime
from enum import Enum

from src.services.gemini_image import GeminiImageClient
from src.llm.openai_compat import create_openai_client

logger = logging.getLogger(__name__)

_LOCAL_PROJECTS: Dict[str, Dict[str, Any]] = {}

async def get_design_llm(vision: bool = False):
    """è·å–è®¾è®¡æ¨¡å—ä½¿ç”¨çš„ LLM å®¢æˆ·ç«¯ï¼ˆå¼€æºç‰ˆï¼šä»…ç¯å¢ƒå˜é‡é…ç½®ï¼‰"""
    api_key = (os.getenv("ALLAPI_KEY") or os.getenv("OPENAI_API_KEY") or "").strip()
    base_url = (os.getenv("ALLAPI_BASE_URL") or "https://nexusapi.cn/v1").strip()
    if not api_key:
        raise RuntimeError("Missing ALLAPI_KEY (set it in your .env).")
    if not base_url:
        raise RuntimeError("Missing ALLAPI_BASE_URL (set it in your .env).")

    model = ((os.getenv("LLM_VISION_MODEL") if vision else os.getenv("LLM_DEFAULT_MODEL")) or "").strip()
    if not model:
        raise RuntimeError("Missing LLM_DEFAULT_MODEL / LLM_VISION_MODEL.")
    return create_openai_client(
        model=model,
        base_url=base_url,
        api_key=api_key,
        temperature=float(os.getenv("LLM_TEMPERATURE", "0.7")),
        max_tokens=int(os.getenv("LLM_MAX_TOKENS", "4096")),
    )

router = APIRouter(prefix="/design", tags=["Design"])


# ============================================
# æ¨¡å‹é…ç½®
# ============================================

class ImageModelProvider(str, Enum):
    GEMINI = "gemini"
    FLUX = "flux"
    DALLE = "dalle"
    MIDJOURNEY = "midjourney"


# å¯ç”¨å›¾åƒæ¨¡å‹é…ç½®
IMAGE_MODELS: Dict[str, Dict[str, Any]] = {
    "gemini-flash": {
        "name": "Gemini Flash",
        "provider": ImageModelProvider.GEMINI,
        "endpoint": "gemini-2.5-flash-image",
        "icon": "âš¡",
        "speed": "fast",
        "quality": "good",
        "available": True,
        "description": "å¿«é€Ÿç”Ÿæˆï¼Œé€‚åˆè¿­ä»£è®¾è®¡"
    },
    "gemini-pro": {
        "name": "Gemini Pro",
        "provider": ImageModelProvider.GEMINI,
        "endpoint": "gemini-3-pro-image-preview",
        "icon": "ğŸ¯",
        "speed": "medium",
        "quality": "excellent",
        "available": True,
        "description": "é«˜è´¨é‡è¾“å‡ºï¼Œç»†èŠ‚ä¸°å¯Œ"
    },
    "flux-pro": {
        "name": "Flux Pro",
        "provider": ImageModelProvider.FLUX,
        "endpoint": "flux-pro",
        "icon": "ğŸ¨",
        "speed": "medium",
        "quality": "excellent",
        "available": False,  # å¾…ç”¨æˆ·æä¾› API
        "description": "è‰ºæœ¯é£æ ¼ç”Ÿæˆä¸“å®¶"
    },
    "dall-e-3": {
        "name": "DALL-E 3",
        "provider": ImageModelProvider.DALLE,
        "endpoint": "dall-e-3",
        "icon": "ğŸ–¼ï¸",
        "speed": "medium",
        "quality": "excellent",
        "available": False,  # å¾…ç”¨æˆ·æä¾› API
        "description": "OpenAI æœ€æ–°å›¾åƒæ¨¡å‹"
    },
}

# è§†é¢‘æ¨¡å‹é…ç½®ï¼ˆé¢„ç•™ï¼‰
VIDEO_MODELS: Dict[str, Dict[str, Any]] = {
    "veo-3": {
        "name": "Veo 3.1",
        "provider": "google",
        "icon": "ğŸ¬",
        "available": False,
        "description": "Google è§†é¢‘ç”Ÿæˆ"
    },
    "sora-2": {
        "name": "Sora 2",
        "provider": "openai",
        "icon": "ğŸ¥",
        "available": False,
        "description": "OpenAI è§†é¢‘ç”Ÿæˆ"
    },
    "hailuo": {
        "name": "Hailuo 2.3",
        "provider": "minimax",
        "icon": "ğŸŒŠ",
        "available": False,
        "description": "MiniMax è§†é¢‘ç”Ÿæˆ"
    },
    "kling": {
        "name": "Kling o1",
        "provider": "kuaishou",
        "icon": "ğŸ­",
        "available": False,
        "description": "å¿«æ‰‹å¯çµè§†é¢‘ç”Ÿæˆ"
    },
}


# ============================================
# è¯·æ±‚/å“åº”æ¨¡å‹
# ============================================

class ImageGenerationRequest(BaseModel):
    """å›¾åƒç”Ÿæˆè¯·æ±‚"""
    prompt: str = Field(..., description="å›¾åƒæè¿°æç¤ºè¯")
    resolution: str = Field("1K", description="åˆ†è¾¨ç‡: 1K, 2K, 4K")
    aspect_ratio: str = Field("1:1", description="å®½é«˜æ¯”: 1:1, 4:3, 16:9, 9:16, 3:4")
    reference_image: Optional[str] = Field(None, description="å‚è€ƒå›¾ç‰‡ base64")
    model: str = Field("gemini-flash", description="æ¨¡å‹ID")


class ImageGenerationResponse(BaseModel):
    """å›¾åƒç”Ÿæˆå“åº”"""
    image_base64: str
    width: int
    height: int
    model_used: str


class ModelInfo(BaseModel):
    """æ¨¡å‹ä¿¡æ¯"""
    id: str
    name: str
    icon: str
    speed: str
    quality: str
    available: bool
    description: str


class ModelsResponse(BaseModel):
    """æ¨¡å‹åˆ—è¡¨å“åº”"""
    image_models: List[ModelInfo]
    video_models: List[ModelInfo]


class DesignChatMessage(BaseModel):
    """å¯¹è¯æ¶ˆæ¯"""
    role: str  # 'user' | 'assistant'
    content: str


class DesignAction(BaseModel):
    """AI å»ºè®®çš„æ“ä½œ"""
    type: str  # 'generate_image' | 'edit_element' | 'suggestion' | 'none'
    data: Optional[Dict[str, Any]] = None


class DesignChatRequest(BaseModel):
    """AI è®¾è®¡å¯¹è¯è¯·æ±‚"""
    message: str = Field(..., description="ç”¨æˆ·æ¶ˆæ¯")
    conversation_history: Optional[List[DesignChatMessage]] = Field(None, description="å¯¹è¯å†å²")
    canvas_state: Optional[str] = Field(None, description="å½“å‰ç”»å¸ƒçŠ¶æ€æè¿°")
    model: Optional[str] = Field(None, description="å¯é€‰ï¼šæŒ‡å®šæœ¬æ¬¡å¯¹è¯ä½¿ç”¨çš„ LLM æ¨¡å‹")
    enable_web_search: bool = Field(False, description="æ˜¯å¦å¯ç”¨è”ç½‘æœç´¢ï¼ˆä¸º LLM æä¾›æœç´¢ä¸Šä¸‹æ–‡ï¼‰")


class DesignChatResponse(BaseModel):
    """AI è®¾è®¡å¯¹è¯å“åº”"""
    reply: str
    action: Optional[DesignAction] = None
    optimized_prompt: Optional[str] = None
    suggested_params: Optional[Dict[str, str]] = None


class CanvasElement(BaseModel):
    """ç”»å¸ƒå…ƒç´ """
    id: str
    type: str
    x: float
    y: float
    content: Optional[str] = None
    width: Optional[float] = None
    height: Optional[float] = None
    color: Optional[str] = None
    shapeType: Optional[str] = None
    fontSize: Optional[int] = None
    fontFamily: Optional[str] = None
    points: Optional[List[dict]] = None
    strokeWidth: Optional[int] = None
    referenceImageId: Optional[str] = None
    groupId: Optional[str] = None
    linkedElements: Optional[List[str]] = None
    connectorFrom: Optional[str] = None
    connectorTo: Optional[str] = None
    connectorStyle: Optional[str] = None


class ProjectSaveRequest(BaseModel):
    """é¡¹ç›®ä¿å­˜è¯·æ±‚"""
    id: Optional[str] = None
    name: str = Field(..., description="é¡¹ç›®åç§°")
    elements: List[CanvasElement] = Field(default_factory=list)
    thumbnail: Optional[str] = None


class ProjectResponse(BaseModel):
    """é¡¹ç›®å“åº”"""
    id: str
    name: str
    elements: List[CanvasElement]
    thumbnail: Optional[str] = None
    created_at: str
    updated_at: str


# å…ƒç´ æ‹†åˆ†ç›¸å…³æ¨¡å‹
class TextRegion(BaseModel):
    """æ–‡å­—åŒºåŸŸ"""
    id: str
    text: str
    bbox: List[float]  # [x, y, width, height]
    font_size: Optional[int] = None
    color: Optional[str] = None
    confidence: float


class ImageLayer(BaseModel):
    """å›¾åƒå›¾å±‚"""
    id: str
    type: str  # 'text', 'subject', 'background', 'object'
    mask_base64: str  # è’™ç‰ˆ
    content_base64: Optional[str] = None  # æå–çš„å†…å®¹
    bbox: Optional[List[float]] = None
    metadata: Optional[Dict[str, Any]] = None


class ElementSplitRequest(BaseModel):
    """å…ƒç´ æ‹†åˆ†è¯·æ±‚"""
    image_base64: str = Field(..., description="å¾…æ‹†åˆ†å›¾åƒ base64")
    extract_text: bool = Field(True, description="æ˜¯å¦æå–æ–‡å­—")
    extract_subjects: bool = Field(True, description="æ˜¯å¦æå–ä¸»ä½“")
    extract_background: bool = Field(True, description="æ˜¯å¦æå–èƒŒæ™¯")


class ElementSplitResponse(BaseModel):
    """å…ƒç´ æ‹†åˆ†å“åº”"""
    layers: List[ImageLayer]
    text_regions: List[TextRegion]
    original_width: int
    original_height: int


class TextEditRequest(BaseModel):
    """æ–‡å­—ç¼–è¾‘è¯·æ±‚"""
    image_base64: str = Field(..., description="åŸå§‹å›¾åƒ")
    text_edits: List[Dict[str, Any]] = Field(..., description="æ–‡å­—ç¼–è¾‘æ“ä½œ")
    # text_edits æ ¼å¼: [{"region_id": "...", "new_text": "...", "font_size": 24, "color": "#fff"}]


class TextEditResponse(BaseModel):
    """æ–‡å­—ç¼–è¾‘å“åº”"""
    result_base64: str
    width: int
    height: int


# ============================================
# å›¾åƒåˆ†æç›¸å…³æ¨¡å‹
# ============================================

class DetectedElement(BaseModel):
    """æ£€æµ‹åˆ°çš„å›¾åƒå…ƒç´ """
    id: str
    type: str  # 'text' | 'object' | 'background' | 'person' | 'shape'
    label: str  # ç”¨æˆ·å‹å¥½çš„æ ‡ç­¾
    bbox: List[float]  # [x, y, width, height] ç›¸å¯¹åæ ‡ 0-1
    confidence: float
    content: Optional[str] = None  # æ–‡å­—å†…å®¹ï¼ˆä»… text ç±»å‹ï¼‰
    description: Optional[str] = None  # å…ƒç´ æè¿°


class ImageAnalysisRequest(BaseModel):
    """å›¾åƒåˆ†æè¯·æ±‚"""
    image_base64: str = Field(..., description="å¾…åˆ†æå›¾åƒ base64")
    analysis_type: str = Field("full", description="åˆ†æç±»å‹: full, text_only, objects_only")


class ImageAnalysisResponse(BaseModel):
    """å›¾åƒåˆ†æå“åº”"""
    elements: List[DetectedElement]
    overall_description: str
    suggested_edits: List[str]


class ElementRegenerateRequest(BaseModel):
    """å…ƒç´ é‡æ–°ç”Ÿæˆè¯·æ±‚"""
    original_image_base64: str = Field(..., description="åŸå§‹å›¾åƒ")
    element_id: str = Field(..., description="è¦ä¿®æ”¹çš„å…ƒç´  ID")
    element_bbox: List[float] = Field(..., description="å…ƒç´ è¾¹ç•Œæ¡† [x, y, w, h]")
    modification_prompt: str = Field(..., description="ä¿®æ”¹æè¿°")
    keep_style: bool = Field(True, description="æ˜¯å¦ä¿æŒåŸé£æ ¼")


class ElementRegenerateResponse(BaseModel):
    """å…ƒç´ é‡æ–°ç”Ÿæˆå“åº”"""
    result_base64: str
    width: int
    height: int


# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

def get_dimensions_from_aspect_ratio(aspect_ratio: str, resolution: str) -> tuple:
    """æ ¹æ®å®½é«˜æ¯”å’Œåˆ†è¾¨ç‡è®¡ç®—å°ºå¯¸"""
    base_sizes = {
        "1K": 1024,
        "2K": 2048,
        "4K": 4096
    }
    
    base = base_sizes.get(resolution, 1024)
    
    ratios = {
        "1:1": (1, 1),
        "4:3": (4, 3),
        "3:4": (3, 4),
        "16:9": (16, 9),
        "9:16": (9, 16)
    }
    
    ratio = ratios.get(aspect_ratio, (1, 1))
    
    if ratio[0] >= ratio[1]:
        width = base
        height = int(base * ratio[1] / ratio[0])
    else:
        height = base
        width = int(base * ratio[0] / ratio[1])
    
    return width, height


# ============================================
# API ç«¯ç‚¹ - æ¨¡å‹ç®¡ç†
# ============================================

@router.get("/models", response_model=ModelsResponse)
async def get_available_models():
    """
    è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    """
    image_models = [
        ModelInfo(
            id=model_id,
            name=model["name"],
            icon=model["icon"],
            speed=model["speed"],
            quality=model["quality"],
            available=model["available"],
            description=model["description"]
        )
        for model_id, model in IMAGE_MODELS.items()
    ]
    
    video_models = [
        ModelInfo(
            id=model_id,
            name=model["name"],
            icon=model["icon"],
            speed="medium",
            quality="excellent",
            available=model["available"],
            description=model["description"]
        )
        for model_id, model in VIDEO_MODELS.items()
    ]
    
    return ModelsResponse(
        image_models=image_models,
        video_models=video_models
    )


# ============================================
# API ç«¯ç‚¹ - å›¾åƒç”Ÿæˆ
# ============================================

@router.post("/generate-image", response_model=ImageGenerationResponse)
async def generate_image(request: ImageGenerationRequest):
    """
    ç”Ÿæˆ AI å›¾åƒ
    
    æ”¯æŒå¤šæ¨¡å‹é€‰æ‹©ï¼Œé»˜è®¤ä½¿ç”¨ Gemini Flash
    """
    try:
        # éªŒè¯æ¨¡å‹
        model_config = IMAGE_MODELS.get(request.model)
        if not model_config:
            raise HTTPException(status_code=400, detail=f"æœªçŸ¥æ¨¡å‹: {request.model}")
        
        if not model_config["available"]:
            raise HTTPException(
                status_code=400, 
                detail=f"æ¨¡å‹ {model_config['name']} æš‚ä¸å¯ç”¨ï¼Œè¯·é€‰æ‹©å…¶ä»–æ¨¡å‹"
            )
        
        # ç›®å‰åªæ”¯æŒ Gemini ç³»åˆ—
        if model_config["provider"] != ImageModelProvider.GEMINI:
            raise HTTPException(
                status_code=501,
                detail=f"æ¨¡å‹ {model_config['name']} å³å°†ä¸Šçº¿"
            )
        
        client = GeminiImageClient()
        if not (client.api_key or "").strip():
            raise HTTPException(
                status_code=500,
                detail="design.image is not configured (missing ALLAPI_KEY).",
            )
        
        # å‡†å¤‡å‚è€ƒå›¾ç‰‡
        ref_images = None
        if request.reference_image:
            ref_data = request.reference_image
            if "," in ref_data:
                ref_data = ref_data.split(",")[1]
            ref_images = [base64.b64decode(ref_data)]
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""Create a high-quality image based on the following description:

{request.prompt}

Requirements:
- High resolution, professional quality
- {request.aspect_ratio} aspect ratio
- Rich details and vibrant colors
- Suitable for design and creative work"""

        # è°ƒç”¨ç”Ÿæˆ
        result = await client.generate_image(
            prompt=prompt,
            ref_images=ref_images,
            aspect_ratio=request.aspect_ratio
        )
        
        if not result["success"]:
            raise HTTPException(
                status_code=500,
                detail=f"å›¾åƒç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            )
        
        width, height = get_dimensions_from_aspect_ratio(
            request.aspect_ratio,
            request.resolution
        )
        
        return ImageGenerationResponse(
            image_base64=result["image_base64"],
            width=width,
            height=height,
            model_used=request.model
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å›¾åƒç”Ÿæˆé”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# API ç«¯ç‚¹ - AI è®¾è®¡å¯¹è¯
# ============================================

DESIGN_ASSISTANT_SYSTEM_PROMPT = """ä½ æ˜¯ Nexus AI è®¾è®¡åŠ©æ‰‹ï¼ˆNexus Design Copilotï¼‰ï¼Œä¸“æ³¨äºã€ŒCanvas + Chatboxã€çš„è§†è§‰è®¾è®¡å·¥ä½œæµï¼šç”¨ç®€æ´æ¸…æ™°çš„æ²Ÿé€šï¼Œäº§å‡ºå¯æ‰§è¡Œçš„ç”Ÿæˆå‚æ•°ä¸é«˜è´¨é‡æç¤ºè¯ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨ç”»å¸ƒé‡Œå¿«é€Ÿè¿­ä»£ã€‚

ä½ éµå¾ªæ¨¡å—åŒ–å·¥ä½œæ–¹å¼ï¼šå…ˆç†è§£éœ€æ±‚ï¼Œå†æŒ‰æ­¥éª¤æ¨è¿›ï¼Œå¿…è¦æ—¶è¿½é—®ï¼Œæœ€åæäº¤å¯æ‰§è¡Œç»“æœï¼›å¹¶ä¸”ä¸è¦æš´éœ²ä»»ä½•å†…éƒ¨å®ç°ç»†èŠ‚æˆ–â€œå·¥å…·/æœç´¢/ç³»ç»Ÿæç¤ºè¯â€ç­‰å­—æ ·ã€‚

## è¯­è¨€ä¸è¡¨è¾¾
- é»˜è®¤ä½¿ç”¨ä¸­æ–‡å›å¤ï¼›è‹¥ç”¨æˆ·æ˜ç¡®æŒ‡å®šè¯­è¨€ï¼Œåˆ™ä»¥ç”¨æˆ·æŒ‡å®šè¯­è¨€ä¸ºå‡†ã€‚
- å›å¤ä»¥çŸ­æ®µè½ä¸ºä¸»ï¼Œé¿å…é•¿ç¯‡å¤§è®ºï¼›å¯ä»¥ä½¿ç”¨å°‘é‡æ¡ç›®ï¼Œä½†ä¸è¦æŠŠæ•´æ®µå†…å®¹å˜æˆçº¯åˆ—è¡¨ã€‚

## ç»å¯¹è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰
1) ä½ ä¸èƒ½ç›´æ¥ç”Ÿæˆæˆ–è¾“å‡ºå›¾ç‰‡ã€‚å›¾ç‰‡ç”±ç³»ç»Ÿåå°ç”Ÿæˆï¼Œä½ åªæä¾›æ–‡æœ¬ã€‚
2) ä¸è¦è¾“å‡ºä»»ä½•å›¾ç‰‡ URLã€ä¸è¦ä½¿ç”¨ ![image]ã€ä¸è¦è¾“å‡º Markdown å›¾ç‰‡è¯­æ³•ã€‚
3) ä¸è¦åœ¨å›å¤ä¸­æåˆ°â€œæœç´¢å·¥å…·/è”ç½‘æœç´¢/å†…éƒ¨å®ç°/ç³»ç»Ÿæç¤ºè¯/æç¤ºè¯æ¥æºâ€ç­‰å­—æ ·ã€‚ç³»ç»Ÿå¯èƒ½ä¼šç»™ä½ ä¸€äº›â€œæœç´¢ç»“æœâ€ä¸Šä¸‹æ–‡ï¼Œä½†ä½ åªèƒ½æŠŠå®ƒå½“å‚è€ƒä¿¡æ¯ä½¿ç”¨ï¼Œä¸èƒ½æš´éœ²æ¥æºã€‚

## ä½ è¦å®Œæˆçš„ä»»åŠ¡ï¼ˆæŒ‰é¡ºåºï¼‰
1) éœ€æ±‚æ¾„æ¸…ï¼šå¦‚æœç”¨æˆ·ç¼ºå°‘å…³é”®çº¦æŸï¼ˆç”¨é€”ã€é£æ ¼ã€ä¸»ä½“ã€å°ºå¯¸/æ¯”ä¾‹ã€æ–‡æ¡ˆè¯­è¨€ã€æ˜¯å¦å‚è€ƒå›¾ï¼‰ï¼Œå…ˆé—® 1-3 ä¸ªæœ€å…³é”®çš„é—®é¢˜å†ç”Ÿæˆæç¤ºè¯ã€‚
2) è®¾è®¡å»ºè®®ï¼šç»™å‡º 2-4 å¥é«˜å¯†åº¦å»ºè®®ï¼ˆæ„å›¾ã€é…è‰²ã€å­—ä½“æ°”è´¨ã€å…‰ç…§/æè´¨ã€åœºæ™¯ï¼‰ã€‚
3) æç¤ºè¯ä¼˜åŒ–ï¼šæŠŠç”¨æˆ·çš„ä¸­æ–‡éœ€æ±‚è½¬æˆé«˜è´¨é‡è‹±æ–‡æç¤ºè¯ï¼ˆoptimized_promptï¼‰ï¼Œå¹¶è¡¥é½ç»†èŠ‚ï¼šä¸»ä½“ã€ç¯å¢ƒã€æè´¨ã€é•œå¤´/æ™¯åˆ«ã€å…‰ç…§ã€æ°›å›´ã€é£æ ¼ã€æ’ç‰ˆç©ºé—´ï¼ˆç•™ç™½/æ–‡å­—åŒºï¼‰ã€è´¨é‡å…³é”®è¯ã€‚

## ä½•æ—¶è¾“å‡ºå¯æ‰§è¡Œ JSONï¼ˆéå¸¸é‡è¦ï¼‰
å½“ç”¨æˆ·æ˜ç¡®è¦æ±‚â€œç”Ÿæˆå›¾åƒ/åˆ›å»º/ç”»ä¸€å¼ /è®¾è®¡ä¸€ä¸ª/å¸®æˆ‘å‡ºå›¾/åšä¸€å¼ æµ·æŠ¥/ç”Ÿæˆå°é¢/ç”Ÿæˆ logoâ€ç­‰éœ€è¦ç³»ç»Ÿå‡ºå›¾çš„è¯·æ±‚æ—¶ï¼Œä½ å¿…é¡»åœ¨å›å¤æœ«å°¾è¿½åŠ ä¸”ä»…è¿½åŠ ä¸€ä¸ª JSON ä»£ç å—ï¼ˆå¿…é¡»ä½¿ç”¨ ```json åŒ…è£¹ï¼‰ï¼Œå¹¶ä¸¥æ ¼éµå®ˆå­—æ®µä¸å–å€¼èŒƒå›´ï¼š

```json
{
  "action": "generate_image",
  "optimized_prompt": "English prompt here",
  "resolution": "1K",
  "aspect_ratio": "1:1"
}
```

å­—æ®µè§„åˆ™ï¼š
- actionï¼šåªèƒ½æ˜¯ "generate_image"
- optimized_promptï¼šå¿…é¡»æ˜¯è‹±æ–‡ï¼›ä¸è¦åŒ…å«ä¸­æ–‡ï¼›ä¸è¦åŒ…å« URLï¼›ä¸è¦åŒ…å« JSON æˆ–åå¼•å·ã€‚
- resolutionï¼šåªèƒ½ä» "1K" | "2K" | "4K" é€‰æ‹©ï¼ˆé»˜è®¤ 1Kï¼›å¼ºè°ƒç»†èŠ‚/å°åˆ·/å¤§å›¾æ—¶é€‰ 2K/4Kï¼‰
- aspect_ratioï¼šåªèƒ½ä» "1:1" | "4:3" | "16:9" | "9:16" | "3:4" é€‰æ‹©ï¼ˆæµ·æŠ¥/è¯¦æƒ…é¡µå¸¸ç”¨ 3:4 æˆ– 4:3ï¼›æ¨ªå¹…/å°é¢ 16:9ï¼›çŸ­è§†é¢‘å°é¢ 9:16ï¼‰

å¦‚æœç”¨æˆ·åªæ˜¯è®¨è®ºå»ºè®®ã€è¯„å®¡ã€é…è‰²ã€æ–‡æ¡ˆæ–¹å‘ã€å¸ƒå±€æ–¹æ¡ˆç­‰ï¼Œä¸è¦è¾“å‡º JSONã€‚

## æç¤ºè¯è´¨é‡æ ‡å‡†ï¼ˆoptimized_promptï¼‰
- ç»“æ„ï¼šSubject + Scene + Composition + Lighting + Material + Style + Typography/negative space + Quality
- ç”»è´¨ï¼šä½¿ç”¨ high quality, highly detailed, professional, sharp focus, clean edgesï¼ˆä¸è¦å¼ºè¡Œå†™ 8Kï¼‰
- é£æ ¼ï¼šæ ¹æ®ç”¨æˆ·è¯­æ°”é€‰æ‹© photography / product shot / 3D render / illustration / flat design ç­‰ï¼Œé¿å…é£æ ¼å†²çªã€‚
- æ’ç‰ˆï¼šéœ€è¦æ–‡å­—çš„æµ·æŠ¥/å°é¢ï¼Œè¦å†™æ¸… â€œspace for headline and subheading / clean layout / balanced negative spaceâ€ï¼Œä½†ä¸è¦æŠŠå…·ä½“ä¸­æ–‡æ–‡æ¡ˆå¡è¿› promptï¼Œé™¤éç”¨æˆ·æ˜ç¡®ç»™å‡ºè‹±æ–‡æ–‡æ¡ˆã€‚
- å‚è€ƒå›¾ï¼šå¦‚æœç”¨æˆ·æåˆ°â€œåŸºäºå‚è€ƒå›¾/ä¿æŒæ„å›¾/åŒé£æ ¼â€ï¼Œåœ¨ optimized_prompt ä¸­åŠ å…¥ â€œuse the reference image as composition/style reference, preserve layoutâ€ ç­‰çº¦æŸã€‚

## ç¤ºä¾‹
ç”¨æˆ·ï¼šæˆ‘æƒ³è¦ä¸€ä¸ªå’–å•¡åº—çš„å®£ä¼ æµ·æŠ¥
åŠ©æ‰‹ï¼šå»ºè®®ç”¨æ¸©æš–å¤§åœ°è‰²+å…‹åˆ¶çš„ç°ä»£æ’ç‰ˆï¼›ä¸»ä½“çªå‡ºæ¯å­ä¸æ‹‰èŠ±ï¼ŒèƒŒæ™¯ç”¨æœ¨çº¹ä¸å’–å•¡è±†ç‚¹ç¼€ï¼Œç•™å‡ºæ ‡é¢˜åŒºï¼Œå…‰çº¿ç”¨æŸ”å’Œæ™¨å…‰åˆ¶é€ æ°›å›´ã€‚

```json
{
  "action": "generate_image",
  "optimized_prompt": "A professional coffee shop promotional poster, warm earthy brown and cream color palette, steaming latte art in an elegant ceramic cup on a rustic wooden table, scattered coffee beans, soft natural morning window light, centered composition with balanced negative space for headline and subheading, modern minimalist typography layout, commercial photography style, high quality, highly detailed, sharp focus",
  "resolution": "1K",
  "aspect_ratio": "3:4"
}
```"""


@router.post("/chat", response_model=DesignChatResponse)
async def design_chat(request: DesignChatRequest):
    """
    AI è®¾è®¡å¯¹è¯
    
    ä½¿ç”¨ Grok (grok-4.1) æä¾›æ™ºèƒ½è®¾è®¡å»ºè®®å’Œè‡ªåŠ¨å›¾åƒç”Ÿæˆ
    
    å·¥ä½œæµç¨‹ï¼š
    1. æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯å’Œå¯¹è¯å†å²
    2. LLM ç†è§£éœ€æ±‚å¹¶ä¼˜åŒ–æç¤ºè¯
    3. è¿”å›ç»“æ„åŒ–å“åº”ï¼ŒåŒ…å«å¯æ‰§è¡Œçš„æ“ä½œ
    """
    try:
        import json
        import re
        
        # æ”¯æŒå‰ç«¯é€šè¿‡ @ åˆ‡æ¢æ¨¡å‹ï¼šè‹¥ request.model æä¾›ï¼Œåˆ™è¦†ç›–é»˜è®¤æ¨¡å‹
        if request.model:
            api_key = (os.getenv("ALLAPI_KEY") or os.getenv("OPENAI_API_KEY") or "").strip()
            base_url = (os.getenv("ALLAPI_BASE_URL") or "https://nexusapi.cn/v1").strip()
            if not api_key or not base_url:
                raise RuntimeError("design.chat is not configured (missing ALLAPI_KEY/ALLAPI_BASE_URL).")
            llm = create_openai_client(
                model=str(request.model),
                base_url=base_url,
                api_key=api_key,
                temperature=float(os.getenv("LLM_TEMPERATURE", "0.7")),
                max_tokens=int(os.getenv("LLM_MAX_TOKENS", "4096")),
            )
        else:
            llm = await get_design_llm(vision=False)
        
        messages = [
            {"role": "system", "content": DESIGN_ASSISTANT_SYSTEM_PROMPT}
        ]

        # ğŸŒ è”ç½‘æœç´¢ï¼šå°†æœç´¢ç»“æœä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™ LLMï¼ˆä¸ç›´æ¥å±•ç¤ºç»™ç”¨æˆ·ï¼‰
        if request.enable_web_search and request.message:
            try:
                from src.tools.web_search import create_web_search_tool

                web_search_tool = create_web_search_tool()
                search_result = await web_search_tool.execute(query=request.message, max_results=5)
                if search_result.is_success and isinstance(search_result.output, dict):
                    answer = search_result.output.get("answer", "")
                    results = search_result.output.get("results", []) or []

                    def _clip(text: str, n: int = 220) -> str:
                        text = (text or "").strip()
                        return text if len(text) <= n else text[:n] + "â€¦"

                    lines = []
                    if answer:
                        lines.append(f"æ‘˜è¦ï¼š{_clip(answer, 300)}")
                    for i, item in enumerate(results[:5], start=1):
                        title = item.get("title", "") if isinstance(item, dict) else ""
                        url = item.get("url", "") if isinstance(item, dict) else ""
                        content = item.get("content", "") if isinstance(item, dict) else ""
                        lines.append(f"{i}. {title}\n   {url}\n   {_clip(content)}")

                    messages.append({
                        "role": "system",
                        "content": "ä»¥ä¸‹ä¸ºè”ç½‘æœç´¢ç»“æœï¼ˆä»…ä¾›å‚è€ƒï¼Œä¼˜å…ˆä½¿ç”¨æ›´å¯ä¿¡çš„ä¿¡æ¯æºï¼›ä¸è¦åœ¨å›å¤ä¸­æš´éœ²â€œæœç´¢å·¥å…·/å†…éƒ¨å®ç°â€ç­‰å­—æ ·ï¼‰ï¼š\n\n"
                                   + "\n".join(lines)
                    })
                else:
                    # æœç´¢å¤±è´¥ä¸é˜»æ–­å¯¹è¯
                    logger.warning(f"è”ç½‘æœç´¢å¤±è´¥: {search_result.error}")
            except Exception as se:
                logger.warning(f"è”ç½‘æœç´¢å¼‚å¸¸: {se}")
        
        # æ·»åŠ ç”»å¸ƒçŠ¶æ€ä¸Šä¸‹æ–‡
        if request.canvas_state:
            messages.append({
                "role": "system",
                "content": f"å½“å‰ç”»å¸ƒçŠ¶æ€ï¼š{request.canvas_state}"
            })
        
        # æ·»åŠ å¯¹è¯å†å²
        if request.conversation_history:
            for msg in request.conversation_history[-10:]:  # é™åˆ¶å†å²é•¿åº¦
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })
        
        # æ·»åŠ å½“å‰æ¶ˆæ¯
        messages.append({
            "role": "user",
            "content": request.message
        })
        
        # è°ƒç”¨ LLM
        response = await llm.achat(messages)
        full_reply = response.content if hasattr(response, 'content') else str(response)
        
        # è§£æå“åº”ï¼Œæå– JSON å—
        action = None
        optimized_prompt = None
        suggested_params = None
        reply = full_reply
        
        # å°è¯•æå– JSON å—
        json_pattern = r'```json\s*(\{[\s\S]*?\})\s*```'
        json_match = re.search(json_pattern, full_reply)
        
        if json_match:
            try:
                json_data = json.loads(json_match.group(1))
                
                if json_data.get("action") == "generate_image":
                    action = DesignAction(
                        type="generate_image",
                        data={
                            "resolution": json_data.get("resolution", "1K"),
                            "aspect_ratio": json_data.get("aspect_ratio", "1:1")
                        }
                    )
                    optimized_prompt = json_data.get("optimized_prompt")
                    suggested_params = {
                        "resolution": json_data.get("resolution", "1K"),
                        "aspect_ratio": json_data.get("aspect_ratio", "1:1")
                    }
                    
                # ä»å›å¤ä¸­ç§»é™¤ JSON å—ï¼Œä¿ç•™ç”¨æˆ·å¯è¯»çš„éƒ¨åˆ†
                reply = re.sub(json_pattern, '', full_reply).strip()
                
            except json.JSONDecodeError:
                logger.warning("æ— æ³•è§£æ AI å“åº”ä¸­çš„ JSON å—")
        
        return DesignChatResponse(
            reply=reply,
            action=action,
            optimized_prompt=optimized_prompt,
            suggested_params=suggested_params
        )
        
    except Exception as e:
        logger.error(f"è®¾è®¡å¯¹è¯é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# API ç«¯ç‚¹ - å…ƒç´ æ‹†åˆ†
# ============================================

@router.post("/split-elements", response_model=ElementSplitResponse)
async def split_elements(request: ElementSplitRequest):
    """
    æ‹†åˆ†å›¾åƒå…ƒç´ 
    
    ä½¿ç”¨ AI åˆ†å‰²æ¨¡å‹ï¼ˆSAMï¼‰å°†å›¾åƒæ‹†åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹å›¾å±‚ï¼š
    - æ–‡å­—å±‚
    - ä¸»ä½“å±‚
    - èƒŒæ™¯å±‚
    - å…¶ä»–å¯¹è±¡
    
    æŠ€æœ¯åŸç†ï¼š
    1. ä½¿ç”¨ SAM (Segment Anything Model) è¿›è¡Œè¯­ä¹‰åˆ†å‰²
    2. ä½¿ç”¨ OCR è¯†åˆ«å’Œå®šä½æ–‡å­—
    3. åˆ†ç¦»å„å›¾å±‚å¹¶ç”Ÿæˆè’™ç‰ˆ
    """
    try:
        import json
        import re
        from io import BytesIO
        from PIL import Image, ImageDraw

        # è§£æå›¾åƒï¼ˆbase64ï¼Œæ—  data: å‰ç¼€ï¼‰
        image_data = request.image_base64
        if "," in image_data:
            image_data = image_data.split(",")[1]

        image_bytes = base64.b64decode(image_data)
        with Image.open(BytesIO(image_bytes)) as im0:
            im = im0.convert("RGBA")
        width, height = im.size

        def _clamp(v: float, a: float, b: float) -> float:
            return max(a, min(b, v))

        def _bbox_to_pixels(bbox01: List[float]) -> tuple[int, int, int, int]:
            x, y, w, h = (bbox01 + [0, 0, 0, 0])[:4]
            x = _clamp(float(x), 0.0, 1.0)
            y = _clamp(float(y), 0.0, 1.0)
            w = _clamp(float(w), 0.0, 1.0)
            h = _clamp(float(h), 0.0, 1.0)
            left = int(round(width * x))
            top = int(round(height * y))
            right = int(round(width * (x + w)))
            bottom = int(round(height * (y + h)))
            right = max(left + 1, min(width, right))
            bottom = max(top + 1, min(height, bottom))
            left = max(0, min(width - 1, left))
            top = max(0, min(height - 1, top))
            return left, top, right, bottom

        def _png_base64(img: Image.Image) -> str:
            buf = BytesIO()
            img.save(buf, format="PNG")
            return base64.b64encode(buf.getvalue()).decode("utf-8")

        def _mask_from_bbox(bbox01: List[float]) -> str:
            mask = Image.new("L", (width, height), 0)
            d = ImageDraw.Draw(mask)
            l, t, r, b = _bbox_to_pixels(bbox01)
            d.rectangle([l, t, r, b], fill=255)
            return _png_base64(mask)

        def _crop_content(bbox01: List[float]) -> str:
            l, t, r, b = _bbox_to_pixels(bbox01)
            crop = im.crop((l, t, r, b))
            return _png_base64(crop)

        # ç”¨è§†è§‰æ¨¡å‹åšâ€œå…ƒç´ çº§æ‹†åˆ†â€ï¼ˆbbox çº§ maskï¼‰ï¼Œä¸ä¾èµ– SAM/OCR
        llm = await get_design_llm(vision=True)

        analysis_prompt = """è¯·è¯†åˆ«å›¾åƒä¸­çš„å¯ç¼–è¾‘å…ƒç´ ï¼Œé‡ç‚¹è¿”å› text å…ƒç´ ï¼ˆå« contentï¼‰ä»¥åŠä¸»ä½“å¯¹è±¡/èƒŒæ™¯ï¼ˆbbox 0-1ï¼‰ã€‚
åªè¿”å› JSONï¼š
{
  "elements": [
    {"id":"...", "type":"text|object|background|person|shape", "label":"...", "bbox":[x,y,w,h], "confidence":0-1, "content":"(text only)", "description":"..."}
  ]
}"""

        messages = [{
            "role": "user",
            "content": [
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_data}"}},
                {"type": "text", "text": analysis_prompt},
            ],
        }]

        response = await llm.achat(messages)
        result_text = response.content if hasattr(response, "content") else str(response)

        json_match = re.search(r"```json\\s*([\\s\\S]*?)\\s*```", result_text)
        if json_match:
            result_text = json_match.group(1)

        try:
            analysis_data = json.loads(result_text)
        except json.JSONDecodeError:
            analysis_data = {"elements": []}

        detected = analysis_data.get("elements", []) or []

        # ç”Ÿæˆ text_regionsï¼ˆç”¨äºâ€œå¯ç¼–è¾‘ text layerâ€ï¼‰
        text_regions: List[TextRegion] = []
        if request.extract_text:
            for el in detected:
                if not isinstance(el, dict):
                    continue
                if el.get("type") != "text":
                    continue
                bbox = el.get("bbox") or [0, 0, 1, 1]
                content = el.get("content") or el.get("label") or ""
                est_font = int(max(12, min(180, round(height * float((bbox + [0, 0, 0, 0])[3]) * 0.9))))
                text_regions.append(TextRegion(
                    id=str(el.get("id") or f"text-{len(text_regions)+1:03d}"),
                    text=str(content),
                    bbox=[float(x) for x in (bbox + [0, 0, 0, 0])[:4]],
                    font_size=est_font,
                    color=None,
                    confidence=float(el.get("confidence") or 0.7),
                ))

        # ç”Ÿæˆ layersï¼ˆmask_base64/content_base64/bbox å‡ä¸ºç›¸å¯¹åæ ‡ï¼‰
        layers: List[ImageLayer] = []

        if request.extract_background:
            bg_mask = Image.new("L", (width, height), 255)
            layers.append(ImageLayer(
                id="background-001",
                type="background",
                mask_base64=_png_base64(bg_mask),
                content_base64=None,
                bbox=[0.0, 0.0, 1.0, 1.0],
                metadata={"description": "èƒŒæ™¯å›¾å±‚ï¼ˆbbox çº§è¿‘ä¼¼ï¼‰"},
            ))

        for el in detected:
            if not isinstance(el, dict):
                continue
            t = el.get("type") or "object"
            bbox = el.get("bbox") or [0, 0, 1, 1]
            bbox01 = [float(x) for x in (bbox + [0, 0, 0, 0])[:4]]

            if t == "background":
                continue

            if t == "text" and not request.extract_text:
                continue

            if t != "text" and not request.extract_subjects:
                continue

            layer_type = "text" if t == "text" else ("subject" if t == "person" else "object")
            layer_id = str(el.get("id") or f"{layer_type}-{len(layers)+1:03d}")

            layers.append(ImageLayer(
                id=layer_id,
                type=layer_type,
                mask_base64=_mask_from_bbox(bbox01),
                content_base64=_crop_content(bbox01),
                bbox=bbox01,
                metadata={
                    "label": el.get("label"),
                    "confidence": el.get("confidence"),
                    "description": el.get("description"),
                },
            ))

        return ElementSplitResponse(layers=layers, text_regions=text_regions, original_width=width, original_height=height)
        
    except Exception as e:
        logger.error(f"å…ƒç´ æ‹†åˆ†é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analyze-image", response_model=ImageAnalysisResponse)
async def analyze_image(request: ImageAnalysisRequest):
    """
    åˆ†æå›¾åƒå…ƒç´ 
    
    ä½¿ç”¨ LLM è§†è§‰èƒ½åŠ›åˆ†æå›¾åƒï¼Œè¯†åˆ«ï¼š
    - æ–‡å­—å…ƒç´ åŠå†…å®¹
    - ä¸»ä½“å¯¹è±¡
    - èƒŒæ™¯å…ƒç´ 
    - äººç‰©
    - å½¢çŠ¶å’Œå›¾å½¢
    
    è¿”å›æ¯ä¸ªå…ƒç´ çš„ä½ç½®ã€ç±»å‹å’Œæè¿°
    """
    try:
        import json
        import re
        
        # å›¾åƒåˆ†æéœ€è¦ä½¿ç”¨è§†è§‰æ¨¡å‹
        llm = await get_design_llm(vision=True)
        
        # å‡†å¤‡å›¾åƒæ•°æ®
        image_data = request.image_base64
        if "," in image_data:
            image_data = image_data.split(",")[1]
        
        analysis_prompt = """è¯·ä»”ç»†åˆ†æè¿™å¼ å›¾åƒï¼Œè¯†åˆ«å‡ºæ‰€æœ‰å¯ç¼–è¾‘çš„å…ƒç´ ã€‚

å¯¹äºæ¯ä¸ªå…ƒç´ ï¼Œè¯·æä¾›ï¼š
1. ç±»å‹ (text/object/background/person/shape)
2. æ ‡ç­¾ (ç®€çŸ­çš„ä¸­æ–‡æè¿°ï¼Œå¦‚"æ ‡é¢˜æ–‡å­—"ã€"å’–å•¡æ¯"ã€"æœ¨çº¹èƒŒæ™¯")
3. è¾¹ç•Œæ¡† (ç›¸å¯¹åæ ‡ï¼ŒèŒƒå›´ 0-1ï¼Œæ ¼å¼ [x, y, width, height])
4. ç½®ä¿¡åº¦ (0-1)
5. å†…å®¹ (ä»…æ–‡å­—ç±»å‹éœ€è¦ï¼Œè¯†åˆ«å‡ºçš„æ–‡å­—)
6. æè¿° (è¯¦ç»†çš„ä¸­æ–‡æè¿°)

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼Œç¤ºä¾‹ï¼š
```json
{
  "overall_description": "è¿™æ˜¯ä¸€å¼ å’–å•¡åº—å®£ä¼ æµ·æŠ¥ï¼ŒåŒ…å«æ ‡é¢˜æ–‡å­—ã€å’–å•¡æ¯å›¾åƒå’Œæœ¨çº¹èƒŒæ™¯",
  "elements": [
    {
      "id": "text-001",
      "type": "text",
      "label": "æ ‡é¢˜æ–‡å­—",
      "bbox": [0.2, 0.1, 0.6, 0.15],
      "confidence": 0.95,
      "content": "COFFEE HOUSE",
      "description": "å¤§æ ‡é¢˜æ–‡å­—ï¼Œç™½è‰²ï¼Œç²—ä½“"
    },
    {
      "id": "object-001",
      "type": "object",
      "label": "å’–å•¡æ¯",
      "bbox": [0.3, 0.3, 0.4, 0.5],
      "confidence": 0.92,
      "content": null,
      "description": "ä¸€æ¯æ‹¿é“å’–å•¡ï¼Œå¸¦æœ‰æ‹‰èŠ±è‰ºæœ¯"
    }
  ],
  "suggested_edits": [
    "å¯ä»¥ä¿®æ”¹æ ‡é¢˜æ–‡å­—å†…å®¹æˆ–é¢œè‰²",
    "å¯ä»¥è°ƒæ•´å’–å•¡æ¯çš„ä½ç½®æˆ–å¤§å°",
    "å¯ä»¥æ›¿æ¢èƒŒæ™¯å›¾æ¡ˆ"
  ]
}
```

è¯·åªè¿”å› JSONï¼Œä¸è¦æ·»åŠ å…¶ä»–å†…å®¹ã€‚"""

        # æ„å»ºå¸¦å›¾åƒçš„æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_data}"
                        }
                    },
                    {
                        "type": "text",
                        "text": analysis_prompt
                    }
                ]
            }
        ]
        
        # è°ƒç”¨æ”¯æŒè§†è§‰çš„ LLM
        response = await llm.achat(messages)
        result_text = response.content if hasattr(response, 'content') else str(response)
        
        # è§£æ JSON å“åº”
        json_pattern = r'```json\s*([\s\S]*?)\s*```'
        json_match = re.search(json_pattern, result_text)
        
        if json_match:
            result_text = json_match.group(1)
        
        # å°è¯•ç›´æ¥è§£æ
        try:
            analysis_data = json.loads(result_text)
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
            logger.warning("æ— æ³•è§£æå›¾åƒåˆ†æç»“æœï¼Œè¿”å›é»˜è®¤æ•°æ®")
            analysis_data = {
                "overall_description": "å›¾åƒåˆ†æå®Œæˆ",
                "elements": [
                    {
                        "id": "background-001",
                        "type": "background",
                        "label": "èƒŒæ™¯",
                        "bbox": [0, 0, 1, 1],
                        "confidence": 0.9,
                        "content": None,
                        "description": "å›¾åƒèƒŒæ™¯"
                    }
                ],
                "suggested_edits": ["å¯ä»¥å°è¯•ä¿®æ”¹å›¾åƒå†…å®¹"]
            }
        
        # æ„å»ºå“åº”
        elements = []
        for i, el in enumerate(analysis_data.get("elements", [])):
            elements.append(DetectedElement(
                id=el.get("id", f"element-{i:03d}"),
                type=el.get("type", "object"),
                label=el.get("label", "æœªçŸ¥å…ƒç´ "),
                bbox=el.get("bbox", [0, 0, 1, 1]),
                confidence=el.get("confidence", 0.8),
                content=el.get("content"),
                description=el.get("description")
            ))
        
        return ImageAnalysisResponse(
            elements=elements,
            overall_description=analysis_data.get("overall_description", ""),
            suggested_edits=analysis_data.get("suggested_edits", [])
        )
        
    except Exception as e:
        logger.error(f"å›¾åƒåˆ†æé”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/regenerate-element", response_model=ElementRegenerateResponse)
async def regenerate_element(request: ElementRegenerateRequest):
    """
    é‡æ–°ç”Ÿæˆå›¾åƒä¸­çš„ç‰¹å®šå…ƒç´ 
    
    å·¥ä½œæµç¨‹ï¼š
    1. æ ¹æ®è¾¹ç•Œæ¡†å®šä½å…ƒç´ 
    2. ä½¿ç”¨ inpainting æˆ–åŒºåŸŸé‡ç»˜
    3. æ ¹æ®ç”¨æˆ·æè¿°ç”Ÿæˆæ–°å†…å®¹
    4. åˆæˆåˆ°åŸå›¾
    """
    try:
        # è§£æå›¾åƒ
        image_data = request.original_image_base64
        if "," in image_data:
            image_data = image_data.split(",")[1]
        
        client = GeminiImageClient()
        if not (client.api_key or "").strip():
            raise HTTPException(
                status_code=500,
                detail="design.image is not configured (missing ALLAPI_KEY).",
            )
        
        # æ„å»ºé‡æ–°ç”Ÿæˆæç¤ºè¯
        regenerate_prompt = f"""Edit this image by modifying the element in the specified region.
        
Region (relative coordinates): x={request.element_bbox[0]:.2f}, y={request.element_bbox[1]:.2f}, width={request.element_bbox[2]:.2f}, height={request.element_bbox[3]:.2f}

Modification requested: {request.modification_prompt}

{"Maintain the original artistic style and color palette." if request.keep_style else "Feel free to change the style as needed."}

Create a seamless edit that blends naturally with the rest of the image."""

        # é€‰æ‹©æœ€æ¥è¿‘çš„å®½é«˜æ¯”ï¼Œé¿å…å›ºå®š 1:1 å¯¼è‡´è¾“å‡ºå˜å½¢
        aspect_ratio = "1:1"
        try:
            from PIL import Image
            from io import BytesIO

            with Image.open(BytesIO(base64.b64decode(image_data))) as im:
                w0, h0 = im.size
            r = (w0 / h0) if h0 else 1.0
            candidates = {
                "1:1": 1.0,
                "4:3": 4 / 3,
                "3:4": 3 / 4,
                "16:9": 16 / 9,
                "9:16": 9 / 16,
            }
            aspect_ratio = min(candidates.keys(), key=lambda k: abs(candidates[k] - r))
        except Exception:
            pass

        # è°ƒç”¨å›¾åƒç¼–è¾‘ï¼ˆå½“å‰ä¸º bbox å¼•å¯¼çš„å‚è€ƒå›¾ç¼–è¾‘ï¼›åç»­å¯æ›¿æ¢ä¸ºçœŸæ­£ inpaintingï¼‰
        result = await client.generate_image(
            prompt=regenerate_prompt,
            ref_images=[base64.b64decode(image_data)],
            aspect_ratio=aspect_ratio
        )
        
        if not result["success"]:
            raise HTTPException(
                status_code=500,
                detail=f"å…ƒç´ é‡æ–°ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            )
        
        width = 1024
        height = 1024
        try:
            from PIL import Image
            from io import BytesIO

            img_bytes = base64.b64decode(result["image_base64"])
            with Image.open(BytesIO(img_bytes)) as im:
                width, height = im.size
        except Exception:
            # è§£ç å¤±è´¥ä¸é˜»æ–­ï¼ˆä¿æŒå…¼å®¹ï¼‰
            pass

        return ElementRegenerateResponse(result_base64=result["image_base64"], width=width, height=height)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å…ƒç´ é‡æ–°ç”Ÿæˆé”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/edit-text-in-image", response_model=TextEditResponse)
async def edit_text_in_image(request: TextEditRequest):
    """
    ç¼–è¾‘å›¾åƒä¸­çš„æ–‡å­—
    
    å·¥ä½œæµï¼š
    1. OCR è¯†åˆ«åŸå§‹æ–‡å­—ä½ç½®å’Œå±æ€§
    2. ä½¿ç”¨ Inpainting ç§»é™¤åŸå§‹æ–‡å­—
    3. åœ¨ç›¸åŒä½ç½®æ¸²æŸ“æ–°æ–‡å­—
    4. åˆæˆæœ€ç»ˆå›¾åƒ
    
    è¿™æ˜¯ Lovart "ç¼–è¾‘æ–‡å­—" åŠŸèƒ½çš„æ ¸å¿ƒå®ç°
    """
    try:
        import json
        import re
        from io import BytesIO
        from PIL import Image, ImageDraw, ImageFont

        # è§£æå›¾åƒ
        image_data = request.image_base64
        if "," in image_data:
            image_data = image_data.split(",")[1]

        img_bytes = base64.b64decode(image_data)
        with Image.open(BytesIO(img_bytes)) as im0:
            im = im0.convert("RGBA")
        width, height = im.size

        # å…ˆç”¨è§†è§‰æ¨¡å‹è¯†åˆ« text å…ƒç´ ï¼ˆç”¨ region_id æ˜ å°„ bboxï¼‰
        llm = await get_design_llm(vision=True)
        analysis_prompt = """è¯†åˆ«å›¾åƒä¸­çš„æ‰€æœ‰æ–‡å­—å…ƒç´ ï¼Œè¿”å› JSONï¼š
{
  "elements":[
    {"id":"text-001","type":"text","bbox":[x,y,w,h],"content":"...","confidence":0-1}
  ]
}
åªè¿”å› JSONï¼Œä¸è¦å…¶å®ƒå†…å®¹ã€‚"""

        messages = [{
            "role": "user",
            "content": [
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_data}"}},
                {"type": "text", "text": analysis_prompt},
            ],
        }]
        resp = await llm.achat(messages)
        result_text = resp.content if hasattr(resp, "content") else str(resp)
        m = re.search(r"```json\\s*([\\s\\S]*?)\\s*```", result_text)
        if m:
            result_text = m.group(1)
        try:
            data = json.loads(result_text)
        except json.JSONDecodeError:
            data = {"elements": []}

        bbox_by_id: Dict[str, List[float]] = {}
        for el in data.get("elements", []) or []:
            if not isinstance(el, dict):
                continue
            if el.get("type") != "text":
                continue
            _id = str(el.get("id") or "")
            bbox = el.get("bbox") or None
            if _id and isinstance(bbox, list) and len(bbox) >= 4:
                bbox_by_id[_id] = [float(x) for x in bbox[:4]]

        def clamp(v: float, a: float, b: float) -> float:
            return max(a, min(b, v))

        def bbox_to_pixels(bbox01: List[float]) -> tuple[int, int, int, int]:
            x, y, w, h = (bbox01 + [0, 0, 0, 0])[:4]
            x = clamp(float(x), 0.0, 1.0)
            y = clamp(float(y), 0.0, 1.0)
            w = clamp(float(w), 0.0, 1.0)
            h = clamp(float(h), 0.0, 1.0)
            left = int(round(width * x))
            top = int(round(height * y))
            right = int(round(width * (x + w)))
            bottom = int(round(height * (y + h)))
            right = max(left + 1, min(width, right))
            bottom = max(top + 1, min(height, bottom))
            left = max(0, min(width - 1, left))
            top = max(0, min(height - 1, top))
            return left, top, right, bottom

        def parse_hex(color: str) -> tuple[int, int, int, int]:
            c = (color or "").strip()
            if c.startswith("#"):
                c = c[1:]
            if len(c) == 3:
                c = "".join([ch * 2 for ch in c])
            if len(c) != 6:
                return (255, 255, 255, 255)
            r = int(c[0:2], 16)
            g = int(c[2:4], 16)
            b = int(c[4:6], 16)
            return (r, g, b, 255)

        def estimate_fill(bbox_px: tuple[int, int, int, int]) -> tuple[int, int, int, int]:
            l, t, r, b = bbox_px
            # é‡‡æ · bbox å¤–æ²¿ä¸€åœˆï¼ˆå°½é‡è´´è¿‘èƒŒæ™¯ï¼‰
            pad = 2
            l2 = max(0, l - pad)
            t2 = max(0, t - pad)
            r2 = min(width - 1, r + pad)
            b2 = min(height - 1, b + pad)
            samples = []
            pix = im.load()
            for x in range(l2, r2):
                samples.append(pix[x, t2])
                samples.append(pix[x, b2])
            for y in range(t2, b2):
                samples.append(pix[l2, y])
                samples.append(pix[r2, y])
            if not samples:
                return (255, 255, 255, 255)
            sr = sum(p[0] for p in samples)
            sg = sum(p[1] for p in samples)
            sb = sum(p[2] for p in samples)
            n = len(samples)
            return (int(sr / n), int(sg / n), int(sb / n), 255)

        draw = ImageDraw.Draw(im)

        for edit in request.text_edits or []:
            if not isinstance(edit, dict):
                continue
            region_id = str(edit.get("region_id") or "")
            new_text = str(edit.get("new_text") or "")
            if not region_id or not new_text:
                continue

            bbox01 = edit.get("bbox") if isinstance(edit.get("bbox"), list) else bbox_by_id.get(region_id)
            if not bbox01 or not isinstance(bbox01, list) or len(bbox01) < 4:
                continue

            bbox01 = [float(x) for x in bbox01[:4]]
            l, t, r, b = bbox_to_pixels(bbox01)
            fill = estimate_fill((l, t, r, b))
            draw.rectangle([l, t, r, b], fill=fill)

            size = int(edit.get("font_size") or max(12, round((b - t) * 0.8)))
            size = max(10, min(200, size))
            color = parse_hex(str(edit.get("color") or "#ffffff"))
            try:
                font = ImageFont.truetype("DejaVuSans.ttf", size=size)
            except Exception:
                font = ImageFont.load_default()

            # ç®€å•å·¦ä¸Šå¯¹é½ + padding
            pad = max(2, int(size * 0.15))
            draw.text((l + pad, t + pad), new_text, fill=color, font=font)

        # è¾“å‡º base64 PNG
        out = BytesIO()
        im.save(out, format="PNG")
        result_base64 = base64.b64encode(out.getvalue()).decode("utf-8")
        return TextEditResponse(result_base64=result_base64, width=width, height=height)
        
    except Exception as e:
        logger.error(f"æ–‡å­—ç¼–è¾‘é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# API ç«¯ç‚¹ - é¡¹ç›®ç®¡ç†
# ============================================

@router.post("/projects", response_model=ProjectResponse)
async def save_project(request: ProjectSaveRequest):
    """
    ä¿å­˜è®¾è®¡é¡¹ç›®
    
    å¼€æºç‰ˆï¼šä»…æœ¬åœ°å†…å­˜å­˜å‚¨ï¼ˆä¸ä¾èµ– Supabase/äº‘ç«¯ï¼‰
    """
    try:
        now = datetime.now().isoformat()
        project_id = request.id or f"local_{uuid.uuid4().hex}"
        existing = _LOCAL_PROJECTS.get(project_id) or {}
        created_at = str(existing.get("created_at") or now)

        data: Dict[str, Any] = {
            "id": project_id,
            "name": request.name,
            "elements": request.elements,
            "thumbnail": request.thumbnail,
            "created_at": created_at,
            "updated_at": now,
        }
        _LOCAL_PROJECTS[project_id] = data
        return ProjectResponse(**data)
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¿å­˜é¡¹ç›®é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/projects", response_model=List[ProjectResponse])
async def get_projects():
    """
    è·å–é¡¹ç›®åˆ—è¡¨
    """
    try:
        items = sorted(
            _LOCAL_PROJECTS.values(),
            key=lambda p: str(p.get("updated_at") or ""),
            reverse=True,
        )
        return [ProjectResponse(**p) for p in items]
        
    except Exception as e:
        logger.error(f"è·å–é¡¹ç›®åˆ—è¡¨é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/projects/{project_id}", response_model=ProjectResponse)
async def get_project(project_id: str):
    """
    è·å–å•ä¸ªé¡¹ç›®
    """
    try:
        data = _LOCAL_PROJECTS.get(project_id)
        if not data:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        return ProjectResponse(**data)
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–é¡¹ç›®é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/projects/{project_id}")
async def delete_project(project_id: str):
    """
    åˆ é™¤é¡¹ç›®
    """
    try:
        if project_id in _LOCAL_PROJECTS:
            _LOCAL_PROJECTS.pop(project_id, None)
        return {"deleted": True}
        
    except Exception as e:
        logger.error(f"åˆ é™¤é¡¹ç›®é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# API ç«¯ç‚¹ - è§†é¢‘ç”Ÿæˆï¼ˆé¢„ç•™ï¼‰
# ============================================

@router.post("/generate-video")
async def generate_video(
    prompt: str,
    duration: int = 5,
    model: str = "veo-3",
    reference_image: Optional[str] = None
):
    """
    ç”Ÿæˆ AI è§†é¢‘ï¼ˆé¢„ç•™æ¥å£ï¼‰
    
    æ”¯æŒçš„æ¨¡å‹ï¼šVeo 3.1, Sora 2, Hailuo 2.3, Kling o1
    ç­‰å¾…ç”¨æˆ·æä¾›è§†é¢‘ç”Ÿæˆ API
    """
    model_config = VIDEO_MODELS.get(model)
    if model_config and model_config["available"]:
        # æœªæ¥å®ç°
        pass
    
    raise HTTPException(
        status_code=501,
        detail="è§†é¢‘ç”ŸæˆåŠŸèƒ½å³å°†ä¸Šçº¿ï¼Œè¯·ç¨åå†è¯•"
    )


@router.post("/export")
async def export_canvas(
    elements: List[CanvasElement],
    format: str = "png"
):
    """
    å¯¼å‡ºç”»å¸ƒä¸ºå›¾ç‰‡ï¼ˆé¢„ç•™æ¥å£ï¼‰
    """
    raise HTTPException(
        status_code=501,
        detail="å¯¼å‡ºåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
    )
